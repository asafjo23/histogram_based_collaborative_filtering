{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "from pandas import read_csv\n",
    "from torch.optim import SGD\n",
    "from torch.utils.data import DataLoader\n",
    "from tensorboardX import SummaryWriter\n",
    "from config import DATA_DIR, MODELS_DIR\n",
    "from src.loss import Loss\n",
    "from src.model import HistogramMF\n",
    "from src.runner import Runner\n",
    "from src.create_dataset import create_dataset\n",
    "from src.data_processor import DataProcessor\n",
    "from src.data_encoder import DataEncoder\n",
    "\n",
    "DF_PATH = f\"{DATA_DIR}/BookCrossing/BX-Book-Ratings-With-Histogram_features.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/tf/cy7jlqss4qs8lktmfhln3y5w0000gq/T/ipykernel_18512/2168540578.py:2: DtypeWarning: Columns (1,3,4,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  original_df = read_csv(DF_PATH, skipinitialspace=True, names=columns)\n"
     ]
    }
   ],
   "source": [
    "columns = [\"user_id\", \"item_id\", \"rating\", \"original_mass\", \"total_mass\"]\n",
    "original_df = read_csv(DF_PATH, skipinitialspace=True, names=columns)\n",
    "original_df = original_df.iloc[1:, :]\n",
    "\n",
    "original_df = original_df.astype({\"user_id\": \"int32\"})\n",
    "original_df = original_df.astype({\"item_id\": str})\n",
    "original_df = original_df.astype({\"rating\": \"int32\"})\n",
    "original_df = original_df.astype({\"original_mass\": \"float64\"})\n",
    "original_df = original_df.astype({\"total_mass\": \"float64\"})"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1150/1150 [03:56<00:00,  4.86batch/s, train_loss=0.107] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=1, loss=126.46271296398457\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1150/1150 [04:14<00:00,  4.52batch/s, train_loss=0.108] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=2, loss=116.80160687568862\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1150/1150 [04:07<00:00,  4.65batch/s, train_loss=0.0976]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=3, loss=108.09200614968316\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1150/1150 [04:13<00:00,  4.53batch/s, train_loss=0.093] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=4, loss=100.69215547356235\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1150/1150 [04:30<00:00,  4.25batch/s, train_loss=0.0806]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=5, loss=93.92955021569662\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1150/1150 [04:23<00:00,  4.36batch/s, train_loss=0.0806]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=6, loss=88.12323430574853\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1150/1150 [04:20<00:00,  4.41batch/s, train_loss=0.0746]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=7, loss=82.73913739522304\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1150/1150 [03:57<00:00,  4.84batch/s, train_loss=0.0767]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=8, loss=78.05626472277531\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1150/1150 [03:57<00:00,  4.84batch/s, train_loss=0.066] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=9, loss=73.60863434933397\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1150/1150 [03:57<00:00,  4.84batch/s, train_loss=0.0643]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=10, loss=69.79698466667756\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1150/1150 [03:57<00:00,  4.83batch/s, train_loss=0.0534]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=11, loss=66.33225483194985\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1150/1150 [03:57<00:00,  4.83batch/s, train_loss=0.0584]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=12, loss=63.23476320012412\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1150/1150 [03:57<00:00,  4.85batch/s, train_loss=0.0558]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=13, loss=60.420259927603\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1150/1150 [03:57<00:00,  4.85batch/s, train_loss=0.0501]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=14, loss=57.91521319677888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1150/1150 [03:56<00:00,  4.86batch/s, train_loss=0.0645]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=15, loss=55.606179252233275\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1150/1150 [03:55<00:00,  4.88batch/s, train_loss=0.0452]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=16, loss=53.51069722473927\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1150/1150 [03:55<00:00,  4.89batch/s, train_loss=0.0421]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=17, loss=51.58726173254153\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1150/1150 [03:55<00:00,  4.89batch/s, train_loss=0.0438]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=18, loss=49.95414984160208\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1150/1150 [03:55<00:00,  4.89batch/s, train_loss=0.0428]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=19, loss=48.34943963945828\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1150/1150 [04:02<00:00,  4.74batch/s, train_loss=0.0415]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=20, loss=46.95314278803115\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1150/1150 [03:55<00:00,  4.89batch/s, train_loss=0.0432]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=21, loss=45.65478127362179\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1150/1150 [03:56<00:00,  4.87batch/s, train_loss=0.0385]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=22, loss=44.52379343355622\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1150/1150 [03:55<00:00,  4.88batch/s, train_loss=0.0395]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=23, loss=43.514243885382704\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1150/1150 [04:00<00:00,  4.79batch/s, train_loss=0.0407]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=24, loss=42.60378576224886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1150/1150 [04:00<00:00,  4.77batch/s, train_loss=0.0415]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=25, loss=41.689758625226155\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1150/1150 [04:00<00:00,  4.77batch/s, train_loss=0.0416]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=26, loss=40.8852017771892\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1150/1150 [04:00<00:00,  4.78batch/s, train_loss=0.0342]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=27, loss=40.25177603227672\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1150/1150 [04:02<00:00,  4.74batch/s, train_loss=0.0357]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=28, loss=39.49946111527469\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1150/1150 [04:01<00:00,  4.76batch/s, train_loss=0.0375]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=29, loss=38.837134739998085\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1150/1150 [04:02<00:00,  4.75batch/s, train_loss=0.0329]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=30, loss=38.1259297607129\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "data_encoder = DataEncoder(original_df=original_df)\n",
    "data_processor = DataProcessor(original_df=original_df)\n",
    "\n",
    "n_users = original_df.user_id.nunique()\n",
    "n_items = original_df.item_id.nunique()\n",
    "\n",
    "min_rating = min(original_df.rating.values)\n",
    "max_rating = max(original_df.rating.values)\n",
    "\n",
    "model = HistogramMF(\n",
    "    n_users=n_users,\n",
    "    n_items=n_items,\n",
    "    data_encoder=data_encoder,\n",
    "    data_processor=data_processor,\n",
    "    min_rating=min_rating,\n",
    "    max_rating=max_rating,\n",
    ")\n",
    "\n",
    "if os.path.exists(f\"{MODELS_DIR}/book_crossing/model.pt\"):\n",
    "    model.load_state_dict(torch.load(f\"{MODELS_DIR}/book_crossing/model.pt\"))\n",
    "\n",
    "epochs = 30\n",
    "\n",
    "criterion = Loss()\n",
    "optimizer = SGD(model.parameters(), lr=5, weight_decay=1e-7)\n",
    "runner = Runner(model=model, criterion=criterion, optimizer=optimizer)\n",
    "\n",
    "train_set = create_dataset(data_encoder=data_encoder)\n",
    "train_load = DataLoader(train_set, batch_size=1000, shuffle=True)\n",
    "\n",
    "with SummaryWriter(f\"runs/book_crossing/dev\") as writer:\n",
    "    for epoch in range(epochs):\n",
    "        epoch_loss = runner.train(train_loader=train_load, epoch=epoch, writer=writer)\n",
    "        print(f\"epoch={epoch + 1}, loss={epoch_loss}\")\n",
    "        torch.save(model.state_dict(), f\"{MODELS_DIR}/book_crossing/model.pt\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "   user_id     item_id  rating\n0   276725  034545104X     0.0\n1   276726  0155061224     3.0\n2   276727  0446520802    -0.0\n3   276729  052165615X     3.0\n4   276729  0521795028     4.0",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>user_id</th>\n      <th>item_id</th>\n      <th>rating</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>276725</td>\n      <td>034545104X</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>276726</td>\n      <td>0155061224</td>\n      <td>3.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>276727</td>\n      <td>0446520802</td>\n      <td>-0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>276729</td>\n      <td>052165615X</td>\n      <td>3.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>276729</td>\n      <td>0521795028</td>\n      <td>4.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pandas import DataFrame\n",
    "from collections import namedtuple\n",
    "\n",
    "Row = namedtuple(\"Row\", \"user_id item_id rating\")\n",
    "\n",
    "data_encoder = DataEncoder(original_df=original_df)\n",
    "dataframe_after_mf = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for (index, user_id, item_id, rating, _, _) in original_df.itertuples():\n",
    "        encoded_user_id = data_encoder.get_encoded_user_id(original_id=user_id)\n",
    "        encoded_item_id = data_encoder.get_encoded_item_id(original_id=item_id)\n",
    "\n",
    "        user_id_as_tensor = torch.LongTensor([encoded_user_id])\n",
    "        item_id_as_tensor = torch.LongTensor([encoded_item_id])\n",
    "        output = model(users=user_id_as_tensor, items=item_id_as_tensor,).squeeze()[0]\n",
    "        predicted_rating = torch.round(output).item()\n",
    "\n",
    "        dataframe_after_mf.append(Row(user_id=user_id, item_id=item_id, rating=predicted_rating))\n",
    "\n",
    "df_after_mf = DataFrame(dataframe_after_mf, columns=[\"user_id\", \"item_id\", \"rating\"])\n",
    "df_after_mf.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of hits: 1061273 / 1149780\n"
     ]
    },
    {
     "data": {
      "text/plain": "         user_id     item_id  rating  New rating\n0         276725  034545104X       0         0.0\n2         276727  0446520802       0        -0.0\n3         276729  052165615X       3         3.0\n8         276744  038550120X       7         7.0\n10        276746  0425115801       0        -0.0\n...          ...         ...     ...         ...\n1149773   276704  0806917695       5         5.0\n1149774   276704  0876044011       0         0.0\n1149775   276704  1563526298       9         9.0\n1149776   276706  0679447156       0        -0.0\n1149777   276709  0515107662      10        10.0\n\n[1061273 rows x 4 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>user_id</th>\n      <th>item_id</th>\n      <th>rating</th>\n      <th>New rating</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>276725</td>\n      <td>034545104X</td>\n      <td>0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>276727</td>\n      <td>0446520802</td>\n      <td>0</td>\n      <td>-0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>276729</td>\n      <td>052165615X</td>\n      <td>3</td>\n      <td>3.0</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>276744</td>\n      <td>038550120X</td>\n      <td>7</td>\n      <td>7.0</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>276746</td>\n      <td>0425115801</td>\n      <td>0</td>\n      <td>-0.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1149773</th>\n      <td>276704</td>\n      <td>0806917695</td>\n      <td>5</td>\n      <td>5.0</td>\n    </tr>\n    <tr>\n      <th>1149774</th>\n      <td>276704</td>\n      <td>0876044011</td>\n      <td>0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1149775</th>\n      <td>276704</td>\n      <td>1563526298</td>\n      <td>9</td>\n      <td>9.0</td>\n    </tr>\n    <tr>\n      <th>1149776</th>\n      <td>276706</td>\n      <td>0679447156</td>\n      <td>0</td>\n      <td>-0.0</td>\n    </tr>\n    <tr>\n      <th>1149777</th>\n      <td>276709</td>\n      <td>0515107662</td>\n      <td>10</td>\n      <td>10.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>1061273 rows × 4 columns</p>\n</div>"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compare = original_df[[\"user_id\", \"item_id\", \"rating\"]].reset_index(drop=True)\n",
    "df_after_mf = df_after_mf.reset_index(drop=True)\n",
    "# df_after_mf.head()\n",
    "mask = (compare[\"rating\"] == df_after_mf[\"rating\"])\n",
    "changes = compare[mask].copy()\n",
    "changes[\"New rating\"] = df_after_mf.rating\n",
    "print(f\"Number of hits: {len(changes)} / {len(original_df)}\")\n",
    "changes.head(len(changes))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}