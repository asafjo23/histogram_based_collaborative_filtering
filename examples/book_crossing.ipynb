{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "from pandas import read_csv\n",
    "from torch.optim import SGD\n",
    "from torch.utils.data import DataLoader\n",
    "from tensorboardX import SummaryWriter\n",
    "from config import DATA_DIR, MODELS_DIR\n",
    "from src.loss import Loss\n",
    "from src.model import HistogramMF\n",
    "from src.runner import Runner\n",
    "from src.create_dataset import create_dataset\n",
    "from src.data_processor import DataProcessor\n",
    "from src.data_encoder import DataEncoder\n",
    "\n",
    "DF_PATH = f\"{DATA_DIR}/BookCrossing/BX-Book-Ratings-With-Histogram_features.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/tf/cy7jlqss4qs8lktmfhln3y5w0000gq/T/ipykernel_16628/2168540578.py:2: DtypeWarning: Columns (1,3,4,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  original_df = read_csv(DF_PATH, skipinitialspace=True, names=columns)\n"
     ]
    }
   ],
   "source": [
    "columns = [\"user_id\", \"item_id\", \"rating\", \"original_mass\", \"total_mass\"]\n",
    "original_df = read_csv(DF_PATH, skipinitialspace=True, names=columns)\n",
    "original_df = original_df.iloc[1:, :]\n",
    "\n",
    "original_df = original_df.astype({\"user_id\": \"int32\"})\n",
    "original_df = original_df.astype({\"item_id\": str})\n",
    "original_df = original_df.astype({\"rating\": \"int32\"})\n",
    "original_df = original_df.astype({\"original_mass\": \"float64\"})\n",
    "original_df = original_df.astype({\"total_mass\": \"float64\"})"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▍  | 853/1150 [03:02<00:59,  4.97batch/s, train_loss=0.282]"
     ]
    }
   ],
   "source": [
    "data_encoder = DataEncoder(original_df=original_df)\n",
    "data_processor = DataProcessor(original_df=original_df)\n",
    "\n",
    "n_users = original_df.user_id.nunique()\n",
    "n_items = original_df.item_id.nunique()\n",
    "\n",
    "min_rating = min(original_df.rating.values)\n",
    "max_rating = max(original_df.rating.values)\n",
    "\n",
    "model = HistogramMF(\n",
    "    n_users=n_users,\n",
    "    n_items=n_items,\n",
    "    data_encoder=data_encoder,\n",
    "    data_processor=data_processor,\n",
    "    min_rating=min_rating,\n",
    "    max_rating=max_rating,\n",
    ")\n",
    "\n",
    "if os.path.exists(f\"{MODELS_DIR}/book_crossing/model.pt\"):\n",
    "    model.load_state_dict(torch.load(f\"{MODELS_DIR}/book_crossing/model.pt\"))\n",
    "else:\n",
    "    epochs = 10\n",
    "\n",
    "    criterion = Loss()\n",
    "    optimizer = SGD(model.parameters(), lr=5, weight_decay=1e-7)\n",
    "    runner = Runner(model=model, criterion=criterion, optimizer=optimizer)\n",
    "\n",
    "    train_set = create_dataset(data_encoder=data_encoder)\n",
    "    train_load = DataLoader(train_set, batch_size=1000, shuffle=True)\n",
    "\n",
    "    with SummaryWriter(f\"runs/book_crossing/dev\") as writer:\n",
    "        for epoch in range(epochs):\n",
    "            epoch_loss = runner.train(train_loader=train_load, epoch=epoch, writer=writer)\n",
    "            print(f\"epoch={epoch + 1}, loss={epoch_loss}\")\n",
    "\n",
    "    torch.save(model.state_dict(), f\"{MODELS_DIR}/book_crossing/model.pt\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from pandas import DataFrame\n",
    "from collections import namedtuple\n",
    "\n",
    "Row = namedtuple(\"Row\", \"user_id item_id rating\")\n",
    "\n",
    "data_encoder = DataEncoder(original_df=original_df)\n",
    "dataframe_after_mf = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for (index, user_id, item_id, rating) in original_df.itertuples():\n",
    "        encoded_user_id = data_encoder.get_encoded_user_id(original_id=user_id)\n",
    "        encoded_item_id = data_encoder.get_encoded_item_id(original_id=item_id)\n",
    "\n",
    "        user_id_as_tensor = torch.LongTensor([encoded_user_id])\n",
    "        item_id_as_tensor = torch.LongTensor([encoded_item_id])\n",
    "        output = model(users=user_id_as_tensor, items=item_id_as_tensor,).squeeze()[0]\n",
    "        predicted_rating = torch.round(output).item()\n",
    "\n",
    "        dataframe_after_mf.append(Row(user_id=user_id, item_id=item_id, rating=predicted_rating))\n",
    "\n",
    "df_after_mf = DataFrame(dataframe_after_mf, columns=[\"user_id\", \"item_id\", \"rating\"])\n",
    "df_after_mf.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "mask = (original_df[\"rating\"] == df_after_mf[\"rating\"])\n",
    "changes = original_df[mask].copy()\n",
    "changes[\"New rating\"] = df_after_mf.rating\n",
    "print(f\"Number of hits: {len(changes)} / {len(original_df)}\")\n",
    "changes.head(len(changes))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}