{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "from pandas import read_csv\n",
    "from torch.optim import SGD\n",
    "from torch.utils.data import DataLoader\n",
    "from tensorboardX import SummaryWriter\n",
    "from config import DATA_DIR, MODELS_DIR\n",
    "from src.loss import Loss\n",
    "from src.model import HistogramMF\n",
    "from src.runner import Runner\n",
    "from src.create_dataset import create_dataset\n",
    "from src.data_processor import DataProcessor\n",
    "from src.data_encoder import DataEncoder\n",
    "\n",
    "DF_PATH = f\"{DATA_DIR}/MovieLens/ratings_500k_with_histogram_features.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "   user_id  item_id  rating  original_mass  total_mass\n0        1      296       5           50.5          70\n1        1      306       3           20.5          70\n2        1      307       5           50.5          70\n3        1      665       5           50.5          70\n4        1      899       3           20.5          70",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>user_id</th>\n      <th>item_id</th>\n      <th>rating</th>\n      <th>original_mass</th>\n      <th>total_mass</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>296</td>\n      <td>5</td>\n      <td>50.5</td>\n      <td>70</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>306</td>\n      <td>3</td>\n      <td>20.5</td>\n      <td>70</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>307</td>\n      <td>5</td>\n      <td>50.5</td>\n      <td>70</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>665</td>\n      <td>5</td>\n      <td>50.5</td>\n      <td>70</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>899</td>\n      <td>3</td>\n      <td>20.5</td>\n      <td>70</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns = [\"user_id\", \"item_id\", \"rating\", \"original_mass\", \"total_mass\"]\n",
    "original_df = read_csv(DF_PATH, skipinitialspace=True, usecols=columns)\n",
    "original_df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 6, got 4)",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Input \u001B[0;32mIn [14]\u001B[0m, in \u001B[0;36m<cell line: 2>\u001B[0;34m()\u001B[0m\n\u001B[1;32m      1\u001B[0m data_encoder \u001B[38;5;241m=\u001B[39m DataEncoder(original_df\u001B[38;5;241m=\u001B[39moriginal_df)\n\u001B[0;32m----> 2\u001B[0m data_processor \u001B[38;5;241m=\u001B[39m \u001B[43mDataProcessor\u001B[49m\u001B[43m(\u001B[49m\u001B[43moriginal_df\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moriginal_df\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      4\u001B[0m n_users \u001B[38;5;241m=\u001B[39m original_df\u001B[38;5;241m.\u001B[39muser_id\u001B[38;5;241m.\u001B[39mnunique()\n\u001B[1;32m      5\u001B[0m n_items \u001B[38;5;241m=\u001B[39m original_df\u001B[38;5;241m.\u001B[39mitem_id\u001B[38;5;241m.\u001B[39mnunique()\n",
      "File \u001B[0;32m~/Desktop/Academy/Vision/Project/histogram_based_collaborative_filtering/src/data_processor.py:16\u001B[0m, in \u001B[0;36mDataProcessor.__init__\u001B[0;34m(self, original_df)\u001B[0m\n\u001B[1;32m     10\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmin_rating \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mmin\u001B[39m(original_df\u001B[38;5;241m.\u001B[39mrating\u001B[38;5;241m.\u001B[39mvalues)\n\u001B[1;32m     11\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmax_rating \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mmax\u001B[39m(original_df\u001B[38;5;241m.\u001B[39mrating\u001B[38;5;241m.\u001B[39mvalues)\n\u001B[1;32m     12\u001B[0m (\n\u001B[1;32m     13\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mratings_by_user,\n\u001B[1;32m     14\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhistograms_by_users,\n\u001B[1;32m     15\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mitem_to_index_rating,\n\u001B[0;32m---> 16\u001B[0m ) \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdata_process\u001B[49m\u001B[43m(\u001B[49m\u001B[43moriginal_df\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moriginal_df\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Desktop/Academy/Vision/Project/histogram_based_collaborative_filtering/src/data_processor.py:35\u001B[0m, in \u001B[0;36mDataProcessor.data_process\u001B[0;34m(self, original_df)\u001B[0m\n\u001B[1;32m     31\u001B[0m     ratings_by_users[user_id] \u001B[38;5;241m=\u001B[39m Parameter(ratings_as_tensor, requires_grad\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n\u001B[1;32m     32\u001B[0m     histograms_by_users[user_id] \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mhistc(\n\u001B[1;32m     33\u001B[0m         ratings_as_tensor, bins\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmax_rating, \u001B[38;5;28mmin\u001B[39m\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmin_rating, \u001B[38;5;28mmax\u001B[39m\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmax_rating\n\u001B[1;32m     34\u001B[0m     )\n\u001B[0;32m---> 35\u001B[0m     item_to_index_rating[user_id] \u001B[38;5;241m=\u001B[39m {\n\u001B[1;32m     36\u001B[0m         item_id: i \u001B[38;5;28;01mfor\u001B[39;00m i, (_, _, item_id, _, _, _) \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(group\u001B[38;5;241m.\u001B[39mitertuples())\n\u001B[1;32m     37\u001B[0m     }\n\u001B[1;32m     39\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m ratings_by_users, histograms_by_users, item_to_index_rating\n",
      "File \u001B[0;32m~/Desktop/Academy/Vision/Project/histogram_based_collaborative_filtering/src/data_processor.py:36\u001B[0m, in \u001B[0;36m<dictcomp>\u001B[0;34m(.0)\u001B[0m\n\u001B[1;32m     31\u001B[0m     ratings_by_users[user_id] \u001B[38;5;241m=\u001B[39m Parameter(ratings_as_tensor, requires_grad\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n\u001B[1;32m     32\u001B[0m     histograms_by_users[user_id] \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mhistc(\n\u001B[1;32m     33\u001B[0m         ratings_as_tensor, bins\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmax_rating, \u001B[38;5;28mmin\u001B[39m\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmin_rating, \u001B[38;5;28mmax\u001B[39m\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmax_rating\n\u001B[1;32m     34\u001B[0m     )\n\u001B[1;32m     35\u001B[0m     item_to_index_rating[user_id] \u001B[38;5;241m=\u001B[39m {\n\u001B[0;32m---> 36\u001B[0m         item_id: i \u001B[38;5;28;01mfor\u001B[39;00m i, (_, _, item_id, _, _, _) \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(group\u001B[38;5;241m.\u001B[39mitertuples())\n\u001B[1;32m     37\u001B[0m     }\n\u001B[1;32m     39\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m ratings_by_users, histograms_by_users, item_to_index_rating\n",
      "\u001B[0;31mValueError\u001B[0m: not enough values to unpack (expected 6, got 4)"
     ]
    }
   ],
   "source": [
    "data_encoder = DataEncoder(original_df=original_df)\n",
    "data_processor = DataProcessor(original_df=original_df)\n",
    "\n",
    "n_users = original_df.user_id.nunique()\n",
    "n_items = original_df.item_id.nunique()\n",
    "\n",
    "min_rating = min(original_df.rating.values)\n",
    "max_rating = max(original_df.rating.values)\n",
    "\n",
    "model = HistogramMF(\n",
    "    n_users=n_users,\n",
    "    n_items=n_items,\n",
    "    data_encoder=data_encoder,\n",
    "    data_processor=data_processor,\n",
    "    min_rating=min_rating,\n",
    "    max_rating=max_rating,\n",
    ")\n",
    "\n",
    "if os.path.exists(f\"{MODELS_DIR}/MovieLens/model.pt\"):\n",
    "    model.load_state_dict(torch.load(f\"{MODELS_DIR}/MovieLens/model.pt\"))\n",
    "\n",
    "epochs = 30\n",
    "\n",
    "criterion = Loss()\n",
    "optimizer = SGD(model.parameters(), lr=5, weight_decay=1e-7)\n",
    "runner = Runner(model=model, criterion=criterion, optimizer=optimizer)\n",
    "\n",
    "train_set = create_dataset(data_encoder=data_encoder)\n",
    "train_load = DataLoader(train_set, batch_size=1000, shuffle=True)\n",
    "\n",
    "with SummaryWriter(f\"runs/MovieLens/dev\") as writer:\n",
    "    for epoch in range(epochs):\n",
    "        epoch_loss = runner.train(train_loader=train_load, epoch=epoch, writer=writer)\n",
    "        print(f\"epoch={epoch + 1}, loss={epoch_loss}\")\n",
    "        torch.save(model.state_dict(), f\"{MODELS_DIR}/MovieLens/model.pt\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from pandas import DataFrame\n",
    "from collections import namedtuple\n",
    "\n",
    "Row = namedtuple(\"Row\", \"user_id item_id rating\")\n",
    "\n",
    "data_encoder = DataEncoder(original_df=original_df)\n",
    "dataframe_after_mf = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for (index, user_id, item_id, rating, _, _) in original_df.itertuples():\n",
    "        encoded_user_id = data_encoder.get_encoded_user_id(original_id=user_id)\n",
    "        encoded_item_id = data_encoder.get_encoded_item_id(original_id=item_id)\n",
    "\n",
    "        user_id_as_tensor = torch.LongTensor([encoded_user_id])\n",
    "        item_id_as_tensor = torch.LongTensor([encoded_item_id])\n",
    "        output = model(users=user_id_as_tensor, items=item_id_as_tensor,).squeeze()[0]\n",
    "        predicted_rating = torch.round(output).item()\n",
    "\n",
    "        dataframe_after_mf.append(Row(user_id=user_id, item_id=item_id, rating=predicted_rating))\n",
    "\n",
    "df_after_mf = DataFrame(dataframe_after_mf, columns=[\"user_id\", \"item_id\", \"rating\"])\n",
    "df_after_mf.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "compare = original_df[[\"user_id\", \"item_id\", \"rating\"]].reset_index(drop=True)\n",
    "df_after_mf = df_after_mf.reset_index(drop=True)\n",
    "# df_after_mf.head()\n",
    "mask = (compare[\"rating\"] == df_after_mf[\"rating\"])\n",
    "changes = compare[mask].copy()\n",
    "changes[\"New rating\"] = df_after_mf.rating\n",
    "print(f\"Number of hits: {len(changes)} / {len(original_df)}\")\n",
    "changes.head(len(changes))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}